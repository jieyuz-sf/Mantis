{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoProcessor\n",
    "from mantis.models.conversation import conv_mllava_v1\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "processor = AutoProcessor.from_pretrained(\"llava-hf/llava-1.5-7b-hf\")\n",
    "# subsets = [\"llava_665k_multi\", \"nlvr2\", \"birds-to-words\", \"contrastive_caption\", \"dreamsim\", \"nextqa\", \"star\", \"spot-the-diff\", \"visual_story_telling\", \"lrv\", \"coinstruct\", \"dvqa\", \"docvqa\", \"chartqa\"]\n",
    "subsets = [\"birds-to-words\"]\n",
    "default_conv = conv_mllava_v1.copy()\n",
    "def get_conv_len(item):\n",
    "    default_conv.messages = []\n",
    "    roles = {\"human\": default_conv.roles[0], \"gpt\": default_conv.roles[1], \"user\": default_conv.roles[0], \"assistant\": default_conv.roles[1]}\n",
    "    default_conv.messages = []\n",
    "    source_key = \"conversation\" if \"conversation\" in item else \"conversations\"\n",
    "    for j, sentence in enumerate(item[source_key]):\n",
    "        role = roles[sentence.get(\"from\", sentence.get(\"role\"))]\n",
    "        # assert role == default_conv.roles[j % 2], f\"Role mismatch: {role} != {default_conv.roles[j % 2]}, {j}\"\n",
    "        default_conv.append_message(role, sentence.get(\"content\", sentence.get(\"text\", sentence.get(\"value\", \"\"))))\n",
    "    return len(processor.tokenizer.encode(default_conv.get_prompt()))\n",
    "\n",
    "def get_question_len(question:str):\n",
    "    return len(processor.tokenizer.encode(question))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subset in subsets:\n",
    "    print(f\"------ {subset} ------\")\n",
    "    dataset = load_dataset(\"TIGER-Lab/Mantis-Instruct\", subset, split='train')\n",
    "    lengths = [get_conv_len(item) for item in tqdm(dataset)]\n",
    "    source_key = \"conversation\" if \"conversation\" in dataset[0] else \"conversations\"\n",
    "    print(f\"# Examples: {len(lengths)}\")\n",
    "    print(f\"# Average images: {np.mean([len(item['images']) for item in dataset])}\")\n",
    "    print(f\"# Max images: {np.max([len(item['images']) for item in dataset])}\")\n",
    "    print(f\"# Avg Turns: {np.mean([len(item[source_key]) for item in dataset])}\")\n",
    "    print(f\"# Max Turns: {np.max([len(item[source_key]) for item in dataset])}\")\n",
    "    print(f\"# Avg Text Length: {np.mean(lengths)}\")\n",
    "    print(f\"# Avg Length with image: {np.mean([lengths[i] + 576 * len(dataset[i]['images']) for i in range(len(lengths))])}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ llava_665k_merged ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312611/312611 [04:33<00:00, 1144.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Examples: 312611\n",
      "# Average images: 1.9994018124762085\n",
      "# Max images: 4\n",
      "# Avg Turns: 21.44195821644152\n",
      "# Max Turns: 260\n",
      "# Avg Text Length: 558.4972793663691\n",
      "# Avg Length with image: 1710.1527233526651\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "------ nlvr2 ------\n",
    "/home/aiops/jiangdf/miniconda3/envs/miqa/lib/python3.9/site-packages/datasets/load.py:1454: FutureWarning: The repository for TIGER-Lab/Mantis-Instruct contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/TIGER-Lab/Mantis-Instruct\n",
    "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
    "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
    "  warnings.warn(\n",
    "100%|██████████████████████████████████████████████████████| 86373/86373 [00:21<00:00, 3952.76it/s]\n",
    "# Examples: 86373\n",
    "# Average images: 2.0\n",
    "# Max images: 2\n",
    "# Avg Turns: 2.0\n",
    "# Max Turns: 2\n",
    "# Avg Text Length: 104.96493117062045\n",
    "# Avg Length with image: 1256.9649311706205\n",
    "------ birds-to-words ------\n",
    "/home/aiops/jiangdf/miniconda3/envs/miqa/lib/python3.9/site-packages/datasets/load.py:1454: FutureWarning: The repository for TIGER-Lab/Mantis-Instruct contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/TIGER-Lab/Mantis-Instruct\n",
    "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
    "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
    "  warnings.warn(\n",
    "100%|████████████████████████████████████████████████████████| 2649/2649 [00:00<00:00, 3447.90it/s]\n",
    "# Examples: 2649\n",
    "# Average images: 2.0\n",
    "# Max images: 2\n",
    "# Avg Turns: 2.0\n",
    "# Max Turns: 2\n",
    "# Avg Text Length: 100.68742921857304\n",
    "# Avg Length with image: 1252.687429218573\n",
    "------ contrastive_caption ------\n",
    "100%|███████████████████████████████████████████████████████| 35984/35984 [01:03<00:00, 565.94it/s]\n",
    "# Examples: 35984\n",
    "# Average images: 3.812083148065807\n",
    "# Max images: 8\n",
    "# Avg Turns: 7.624166296131614\n",
    "# Max Turns: 16\n",
    "# Avg Text Length: 871.1644341929747\n",
    "# Avg Length with image: 3066.9243274788796\n",
    "------ dreamsim ------\n",
    "100%|██████████████████████████████████████████████████████| 15941/15941 [00:04<00:00, 3404.04it/s]\n",
    "# Examples: 15941\n",
    "# Average images: 3.0\n",
    "# Max images: 3\n",
    "# Avg Turns: 2.0\n",
    "# Max Turns: 2\n",
    "# Avg Text Length: 102.54607615582461\n",
    "# Avg Length with image: 1830.5460761558245\n",
    "------ nextqa ------\n",
    "100%|█████████████████████████████████████████████████████████| 3870/3870 [00:04<00:00, 935.30it/s]\n",
    "# Examples: 3870\n",
    "# Average images: 8.0\n",
    "# Max images: 8\n",
    "# Avg Turns: 17.639276485788113\n",
    "# Max Turns: 38\n",
    "# Avg Text Length: 572.2147286821705\n",
    "# Avg Length with image: 5180.214728682171\n",
    "------ star ------\n",
    "100%|█████████████████████████████████████████████████████████| 3032/3032 [00:04<00:00, 680.98it/s]\n",
    "# Examples: 3032\n",
    "# Average images: 8.0\n",
    "# Max images: 8\n",
    "# Avg Turns: 30.1655672823219\n",
    "# Max Turns: 232\n",
    "# Avg Text Length: 961.259234828496\n",
    "# Avg Length with image: 5569.259234828496\n",
    "------ spot-the-diff ------\n",
    "100%|████████████████████████████████████████████████████████| 8007/8007 [00:02<00:00, 2916.66it/s]\n",
    "# Examples: 8007\n",
    "# Average images: 2.0\n",
    "# Max images: 2\n",
    "# Avg Turns: 3.993755463969027\n",
    "# Max Turns: 28\n",
    "# Avg Text Length: 120.73398276508055\n",
    "# Avg Length with image: 1272.7339827650806\n",
    "------ visual_story_telling ------\n",
    "100%|█████████████████████████████████████████████████████████| 6661/6661 [00:08<00:00, 803.68it/s]\n",
    "# Examples: 6661\n",
    "# Average images: 20.32772856928389\n",
    "# Max images: 50\n",
    "# Avg Turns: 9.709653205224441\n",
    "# Max Turns: 20\n",
    "# Avg Text Length: 529.7932742831407\n",
    "# Avg Length with image: 12238.564930190661\n",
    "------ lrv ------\n",
    "100%|█████████████████████████████████████████████████████████| 8453/8453 [00:35<00:00, 237.13it/s]\n",
    "# Examples: 8453\n",
    "# Average images: 3.5011238613509996\n",
    "# Max images: 9\n",
    "# Avg Turns: 83.33656689932569\n",
    "# Max Turns: 154\n",
    "# Avg Text Length: 2234.463622382586\n",
    "# Avg Length with image: 4251.110966520762\n",
    "------ coinstruct ------\n",
    "100%|████████████████████████████████████████████████████| 150918/150918 [01:48<00:00, 1395.81it/s]\n",
    "# Examples: 150918\n",
    "# Average images: 2.266906532024013\n",
    "# Max images: 4\n",
    "# Avg Turns: 7.4451026385189305\n",
    "# Max Turns: 58\n",
    "# Avg Text Length: 313.8353542983607\n",
    "# Avg Length with image: 1619.5735167441921\n",
    "------ dvqa ------\n",
    "100%|████████████████████████████████████████████████████| 200000/200000 [02:23<00:00, 1390.70it/s]\n",
    "# Examples: 200000\n",
    "# Average images: 1.0\n",
    "# Max images: 1\n",
    "# Avg Turns: 23.25316\n",
    "# Max Turns: 40\n",
    "# Avg Text Length: 304.306895\n",
    "# Avg Length with image: 880.306895\n",
    "------ docvqa ------\n",
    "100%|██████████████████████████████████████████████████████| 39463/39463 [00:07<00:00, 5190.59it/s]\n",
    "# Examples: 39463\n",
    "# Average images: 1.0\n",
    "# Max images: 1\n",
    "# Avg Turns: 2.0\n",
    "# Max Turns: 2\n",
    "# Avg Text Length: 61.71502419988344\n",
    "# Avg Length with image: 637.7150241998835\n",
    "------ chartqa ------\n",
    "100%|██████████████████████████████████████████████████████| 28299/28299 [00:05<00:00, 5104.47it/s]\n",
    "# Examples: 28299\n",
    "# Average images: 1.0\n",
    "# Max images: 1\n",
    "# Avg Turns: 2.0\n",
    "# Max Turns: 2\n",
    "# Avg Text Length: 66.11519841690519\n",
    "# Avg Length with image: 642.1151984169052\n",
    "------ llava_665k_multi ------\n",
    "# Examples: 312611\n",
    "# Average images: 1.9994018124762085\n",
    "# Max images: 4\n",
    "# Avg Turns: 21.44195821644152\n",
    "# Max Turns: 260\n",
    "# Avg Text Length: 558.4972793663691\n",
    "# Avg Length with image: 1710.1527233526651\n",
    "------ imagecode ------\n",
    "# Examples: 16594\n",
    "# Average images: 10.0\n",
    "# Max images: 10\n",
    "# Avg Turns: 2.0\n",
    "# Max Turns: 2\n",
    "# Avg Text Length: 125.86386645775582\n",
    "# Avg Length with image: 5885.863866457756\n",
    "------ multi_vqa ------\n",
    "# Examples: 4993\n",
    "# Average images: 4.019026637292209\n",
    "# Max images: 6\n",
    "# Avg Turns: 19.709593430803125\n",
    "# Max Turns: 22\n",
    "# Avg Text Length: 1102.1363909473262\n",
    "# Avg Length with image: 3417.0957340276386\n",
    "------ iconqa ------\n",
    "# Examples: 64462\n",
    "# Average images: 2.401430300021718\n",
    "# Max images: 6\n",
    "# Avg Turns: 2.0\n",
    "# Max Turns: 2\n",
    "# Avg Text Length: 70.62872700195464\n",
    "# Avg Length with image: 1453.8525798144644\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ human_eval ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 217/217 [00:16<00:00, 13.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Examples: 217\n",
      "# Average images: 2.488479262672811\n",
      "# Max images: 5\n",
      "# Avg Text Length: 21.967741935483872\n",
      "# Avg Length with image: 1455.331797235023\n",
      "------ birds-to-words ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 337/337 [00:06<00:00, 54.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Examples: 337\n",
      "# Average images: 2.0\n",
      "# Max images: 2\n",
      "# Avg Text Length: 13.02373887240356\n",
      "# Avg Length with image: 1165.0237388724036\n",
      "------ nlvr2 ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6967/6967 [08:00<00:00, 14.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Examples: 6967\n",
      "# Average images: 2.0\n",
      "# Max images: 2\n",
      "# Avg Text Length: 37.554901679345484\n",
      "# Avg Length with image: 1189.5549016793454\n"
     ]
    }
   ],
   "source": [
    "eval_subsets = [\"mantis_eval\", \"birds-to-words\", \"nlvr2\"]\n",
    "from datasets import load_dataset\n",
    "for subset in eval_subsets:\n",
    "    print(f\"------ {subset} ------\")\n",
    "    dataset = load_dataset(\"Mantis-VL/MIQA_eval\", subset, split='test')\n",
    "    lengths = [get_question_len(item[\"question\"]) for item in tqdm(dataset)]\n",
    "    print(f\"# Examples: {len(lengths)}\")\n",
    "    print(f\"# Average images: {np.mean([len(item['images']) for item in dataset])}\")\n",
    "    print(f\"# Max images: {np.max([len(item['images']) for item in dataset])}\")\n",
    "    print(f\"# Avg Text Length: {np.mean(lengths)}\")\n",
    "    print(f\"# Avg Length with image: {np.mean([lengths[i] + 576 * len(dataset[i]['images']) for i in range(len(lengths))])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Art_Style: 100%|██████████| 117/117 [00:05<00:00, 22.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Art_Style ------\n",
      "# Examples: 117\n",
      "# Average images: 3.0\n",
      "# Max images: 3\n",
      "# Avg Text Length: 12.0\n",
      "# Avg Length with image: 1740.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Counting: 100%|██████████| 120/120 [00:00<00:00, 709.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Counting ------\n",
      "# Examples: 120\n",
      "# Average images: 1.0\n",
      "# Max images: 1\n",
      "# Avg Text Length: 11.466666666666667\n",
      "# Avg Length with image: 587.4666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Forensic_Detection: 100%|██████████| 132/132 [00:00<00:00, 155.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Forensic_Detection ------\n",
      "# Examples: 132\n",
      "# Average images: 4.0\n",
      "# Max images: 4\n",
      "# Avg Text Length: 12.0\n",
      "# Avg Length with image: 2316.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Functional_Correspondence: 100%|██████████| 130/130 [00:01<00:00, 100.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Functional_Correspondence ------\n",
      "# Examples: 130\n",
      "# Average images: 2.0\n",
      "# Max images: 2\n",
      "# Avg Text Length: 10.0\n",
      "# Avg Length with image: 1162.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IQ_Test: 100%|██████████| 150/150 [00:00<00:00, 570.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ IQ_Test ------\n",
      "# Examples: 150\n",
      "# Average images: 1.0\n",
      "# Max images: 1\n",
      "# Avg Text Length: 16.1\n",
      "# Avg Length with image: 592.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jigsaw: 100%|██████████| 150/150 [00:00<00:00, 685.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Jigsaw ------\n",
      "# Examples: 150\n",
      "# Average images: 3.0\n",
      "# Max images: 3\n",
      "# Avg Text Length: 12.0\n",
      "# Avg Length with image: 1740.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multi-view_Reasoning: 100%|██████████| 133/133 [00:00<00:00, 286.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Multi-view_Reasoning ------\n",
      "# Examples: 133\n",
      "# Average images: 2.0\n",
      "# Max images: 2\n",
      "# Avg Text Length: 46.0\n",
      "# Avg Length with image: 1198.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Object_Localization: 100%|██████████| 122/122 [00:00<00:00, 439.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Object_Localization ------\n",
      "# Examples: 122\n",
      "# Average images: 1.0\n",
      "# Max images: 1\n",
      "# Avg Text Length: 18.270491803278688\n",
      "# Avg Length with image: 594.2704918032787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Relative_Depth: 100%|██████████| 124/124 [00:00<00:00, 714.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Relative_Depth ------\n",
      "# Examples: 124\n",
      "# Average images: 1.0\n",
      "# Max images: 1\n",
      "# Avg Text Length: 9.0\n",
      "# Avg Length with image: 585.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Relative_Reflectance: 100%|██████████| 134/134 [00:00<00:00, 199.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Relative_Reflectance ------\n",
      "# Examples: 134\n",
      "# Average images: 1.0\n",
      "# Max images: 1\n",
      "# Avg Text Length: 33.0\n",
      "# Avg Length with image: 609.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Semantic_Correspondence: 100%|██████████| 139/139 [00:01<00:00, 87.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Semantic_Correspondence ------\n",
      "# Examples: 139\n",
      "# Average images: 2.0\n",
      "# Max images: 2\n",
      "# Avg Text Length: 10.0\n",
      "# Avg Length with image: 1162.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Spatial_Relation: 100%|██████████| 143/143 [00:00<00:00, 599.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Spatial_Relation ------\n",
      "# Examples: 143\n",
      "# Average images: 1.0\n",
      "# Max images: 1\n",
      "# Avg Text Length: 10.258741258741258\n",
      "# Avg Length with image: 586.2587412587412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Visual_Correspondence: 100%|██████████| 172/172 [00:02<00:00, 79.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Visual_Correspondence ------\n",
      "# Examples: 172\n",
      "# Average images: 2.0\n",
      "# Max images: 2\n",
      "# Avg Text Length: 10.0\n",
      "# Avg Length with image: 1162.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Visual_Similarity: 100%|██████████| 135/135 [00:01<00:00, 114.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Visual_Similarity ------\n",
      "# Examples: 135\n",
      "# Average images: 3.0\n",
      "# Max images: 3\n",
      "# Avg Text Length: 11.0\n",
      "# Avg Length with image: 1739.0\n",
      "------ all ------\n",
      "# Examples: 1901\n",
      "# Average images: 1.9331930562861652\n",
      "# Max images: 4\n",
      "# Avg Text Length: 15.689637033140452\n",
      "# Avg Length with image: 1129.2088374539717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import get_dataset_config_names, load_dataset\n",
    "from tqdm import tqdm\n",
    "configs = get_dataset_config_names(\"BLINK-Benchmark/BLINK\")\n",
    "config_items = {}\n",
    "for config in configs:\n",
    "    config_items[config] = []\n",
    "    config_dataset = load_dataset(\"BLINK-Benchmark/BLINK\", config, split='val')\n",
    "    for item in tqdm(config_dataset, desc=config):\n",
    "        num_of_images = len([item[x] for x in [f\"image_{i}\" for i in range(1, 5)] if item[x] is not None])\n",
    "        config_items[config].append({\n",
    "            \"text_length\": get_question_len(item[\"question\"]),\n",
    "            \"num_of_images\": num_of_images\n",
    "        })\n",
    "    print(f\"------ {config} ------\")\n",
    "    print(f\"# Examples: {len(config_items[config])}\")\n",
    "    print(f\"# Average images: {np.mean([item['num_of_images'] for item in config_items[config]])}\")\n",
    "    print(f\"# Max images: {np.max([item['num_of_images'] for item in config_items[config]])}\")\n",
    "    print(f\"# Avg Text Length: {np.mean([item['text_length'] for item in config_items[config]])}\")\n",
    "    print(f\"# Avg Length with image: {np.mean([item['text_length'] + 576 * item['num_of_images'] for item in config_items[config]])}\")\n",
    "\n",
    "# all\n",
    "all_items = [item for config in config_items for item in config_items[config]]\n",
    "print(f\"------ all ------\")\n",
    "print(f\"# Examples: {len(all_items)}\")\n",
    "print(f\"# Average images: {np.mean([item['num_of_images'] for item in all_items])}\")\n",
    "print(f\"# Max images: {np.max([item['num_of_images'] for item in all_items])}\")\n",
    "print(f\"# Avg Text Length: {np.mean([item['text_length'] for item in all_items])}\")\n",
    "print(f\"# Avg Length with image: {np.mean([item['text_length'] + 576 * item['num_of_images'] for item in all_items])}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 16920.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ mvbench/MVBench/json/counterfactual_inference.json ------\n",
      "# Examples: 200\n",
      "# Average images: 8.0\n",
      "# Max images: 8\n",
      "# Avg Text Length: 11.665\n",
      "# Avg Length with image: 4619.665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 7711.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ mvbench/MVBench/json/egocentric_navigation.json ------\n",
      "# Examples: 200\n",
      "# Average images: 8.0\n",
      "# Max images: 8\n",
      "# Avg Text Length: 51.755\n",
      "# Avg Length with image: 4659.755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 24635.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ mvbench/MVBench/json/moving_count.json ------\n",
      "# Examples: 200\n",
      "# Average images: 8.0\n",
      "# Max images: 8\n",
      "# Avg Text Length: 10.16\n",
      "# Avg Length with image: 4618.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 18131.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ mvbench/MVBench/json/object_shuffle.json ------\n",
      "# Examples: 200\n",
      "# Average images: 8.0\n",
      "# Max images: 8\n",
      "# Avg Text Length: 35.0\n",
      "# Avg Length with image: 4643.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 24836.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ mvbench/MVBench/json/scene_transition.json ------\n",
      "# Examples: 200\n",
      "# Average images: 8.0\n",
      "# Max images: 8\n",
      "# Avg Text Length: 14.605\n",
      "# Avg Length with image: 4622.605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 30424.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ mvbench/MVBench/json/action_prediction.json ------\n",
      "# Examples: 200\n",
      "# Average images: 8.0\n",
      "# Max images: 8\n",
      "# Avg Text Length: 8.55\n",
      "# Avg Length with image: 4616.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 14714.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ mvbench/MVBench/json/action_localization.json ------\n",
      "# Examples: 200\n",
      "# Average images: 8.0\n",
      "# Max images: 8\n",
      "# Avg Text Length: 21.135\n",
      "# Avg Length with image: 4629.135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 22692.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ mvbench/MVBench/json/state_change.json ------\n",
      "# Examples: 200\n",
      "# Average images: 8.0\n",
      "# Max images: 8\n",
      "# Avg Text Length: 20.07\n",
      "# Avg Length with image: 4628.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 19344.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ mvbench/MVBench/json/moving_attribute.json ------\n",
      "# Examples: 200\n",
      "# Average images: 8.0\n",
      "# Max images: 8\n",
      "# Avg Text Length: 14.165\n",
      "# Avg Length with image: 4622.165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 25602.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ mvbench/MVBench/json/character_order.json ------\n",
      "# Examples: 200\n",
      "# Average images: 8.0\n",
      "# Max images: 8\n",
      "# Avg Text Length: 12.605\n",
      "# Avg Length with image: 4620.605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 23233.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ mvbench/MVBench/json/action_antonym.json ------\n",
      "# Examples: 200\n",
      "# Average images: 8.0\n",
      "# Max images: 8\n",
      "# Avg Text Length: 12.2\n",
      "# Avg Length with image: 4620.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 15901.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ mvbench/MVBench/json/episodic_reasoning.json ------\n",
      "# Examples: 200\n",
      "# Average images: 8.0\n",
      "# Max images: 8\n",
      "# Avg Text Length: 18.78\n",
      "# Avg Length with image: 4626.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 27622.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ mvbench/MVBench/json/fine_grained_pose.json ------\n",
      "# Examples: 200\n",
      "# Average images: 8.0\n",
      "# Max images: 8\n",
      "# Avg Text Length: 11.83\n",
      "# Avg Length with image: 4619.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 17592.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ mvbench/MVBench/json/unexpected_action.json ------\n",
      "# Examples: 200\n",
      "# Average images: 8.0\n",
      "# Max images: 8\n",
      "# Avg Text Length: 14.795\n",
      "# Avg Length with image: 4622.795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 22657.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ mvbench/MVBench/json/object_existence.json ------\n",
      "# Examples: 200\n",
      "# Average images: 8.0\n",
      "# Max images: 8\n",
      "# Avg Text Length: 11.315\n",
      "# Avg Length with image: 4619.315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 23588.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ mvbench/MVBench/json/action_sequence.json ------\n",
      "# Examples: 200\n",
      "# Average images: 8.0\n",
      "# Max images: 8\n",
      "# Avg Text Length: 11.62\n",
      "# Avg Length with image: 4619.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 23490.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ mvbench/MVBench/json/action_count.json ------\n",
      "# Examples: 200\n",
      "# Average images: 8.0\n",
      "# Max images: 8\n",
      "# Avg Text Length: 15.625\n",
      "# Avg Length with image: 4623.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 27097.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ mvbench/MVBench/json/fine_grained_action.json ------\n",
      "# Examples: 200\n",
      "# Average images: 8.0\n",
      "# Max images: 8\n",
      "# Avg Text Length: 12.5\n",
      "# Avg Length with image: 4620.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 22409.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ mvbench/MVBench/json/moving_direction.json ------\n",
      "# Examples: 200\n",
      "# Average images: 8.0\n",
      "# Max images: 8\n",
      "# Avg Text Length: 14.455\n",
      "# Avg Length with image: 4622.455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 28078.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ mvbench/MVBench/json/object_interaction.json ------\n",
      "# Examples: 200\n",
      "# Average images: 8.0\n",
      "# Max images: 8\n",
      "# Avg Text Length: 9.775\n",
      "# Avg Length with image: 4617.775\n",
      "------ all ------\n",
      "# Examples: 4000\n",
      "# Average images: 8.0\n",
      "# Max images: 8\n",
      "# Avg Text Length: 16.63025\n",
      "# Avg Length with image: 4624.63025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "# MVbench\n",
    "import json\n",
    "json_dir = Path(\"./mvbench/MVBench/json\")\n",
    "new_data = []\n",
    "for json_file in json_dir.glob(\"*.json\"):\n",
    "    with open(json_file, \"r\") as f:\n",
    "        subset_data = json.load(f)\n",
    "    subset_new_data = []\n",
    "    for item in tqdm(subset_data):\n",
    "        subset_new_data.append({\n",
    "            \"text_length\": get_question_len(item[\"question\"]),\n",
    "            \"num_of_images\": 8\n",
    "        })\n",
    "    print(f\"------ {json_file} ------\")\n",
    "    print(f\"# Examples: {len(subset_new_data)}\")\n",
    "    print(f\"# Average images: {np.mean([item['num_of_images'] for item in subset_new_data])}\")\n",
    "    print(f\"# Max images: {np.max([item['num_of_images'] for item in subset_new_data])}\")\n",
    "    print(f\"# Avg Text Length: {np.mean([item['text_length'] for item in subset_new_data])}\")\n",
    "    print(f\"# Avg Length with image: {np.mean([item['text_length'] + 576 * item['num_of_images'] for item in subset_new_data])}\")\n",
    "    new_data.extend(subset_new_data)\n",
    "        \n",
    "print(f\"------ all ------\")\n",
    "print(f\"# Examples: {len(new_data)}\")\n",
    "print(f\"# Average images: {np.mean([item['num_of_images'] for item in new_data])}\")\n",
    "print(f\"# Max images: {np.max([item['num_of_images'] for item in new_data])}\")\n",
    "print(f\"# Avg Text Length: {np.mean([item['text_length'] for item in new_data])}\")\n",
    "print(f\"# Avg Length with image: {np.mean([item['text_length'] + 576 * item['num_of_images'] for item in new_data])}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Qbench A1-pair-dev ------\n",
      "# Examples: 1000\n",
      "# Average images: 2.0\n",
      "# Max images: 2\n",
      "# Avg Text Length: 14.836\n",
      "# Avg Length with image: 1166.836\n"
     ]
    }
   ],
   "source": [
    "# Qbench\n",
    "import json\n",
    "with open('./qbench2/data/q-bench2-a1-single-dev.json') as f:\n",
    "    data = json.load(f)\n",
    "for item in data:\n",
    "    item[\"text_length\"] = get_question_len(item[\"question\"])\n",
    "    item[\"num_of_images\"] = len(item[\"images\"])\n",
    "print(f\"------ Qbench A1-pair-dev ------\")\n",
    "print(f\"# Examples: {len(data)}\")\n",
    "print(f\"# Average images: {np.mean([item['num_of_images'] for item in data])}\")\n",
    "print(f\"# Max images: {np.max([item['num_of_images'] for item in data])}\")\n",
    "print(f\"# Avg Text Length: {np.mean([item['text_length'] for item in data])}\")\n",
    "print(f\"# Avg Length with image: {np.mean([item['text_length'] + 576 * item['num_of_images'] for item in data])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "miqa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
